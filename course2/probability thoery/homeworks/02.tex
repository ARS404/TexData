\subsection{Домашка вторая}

\i Для начала решим задачу, когда шары различимы. Рассмотрим матожидание индикатора $P_i$ того, что в $i$-том ящике ровно один шар, тогда искомое матожидание будет
равно сумме $EP_i$. Для того, чтобы в ящике оказался ровно один шар нам достаточно выбрать этот шар ($k$ способов) и разложить остальные вдругие ящики 
($(m-1)^{k-1}$ способов).
Так как все разбиения шаров п оящикам равновероятны, то мы получаем, что вероятность такого индикатора равна 
\[\frac{k(m-1)^{k-1}}{m^k}.\]
Осталось просуммировать и получить: 
    \[E\xi = m \cdot \frac{k(m-1)^{k-1}}{m^k} = k \cdot \brackets{\frac{m-1}{m}}^{k-1}.\]
Теперь посчитаем $D\xi$ по определению это 
\begin{gather*}
    E(\xi - E\xi)^2 = E\xi^2 - \brackets{E\xi}^2 = E\xi^2 - k^2\cdot\brackets{\frac{m-1}{m}}^{2k-2} = 
    E(\sum_{i=1}^{m}P_i)^2 - k^2\cdot\brackets{\frac{m-1}{m}}^{2k-2} = \\ 
    = \brackets{m\cdot\frac{k(m-1)^{k-1}}{m^k}}^2 - k^2\cdot\brackets{\frac{m-1}{m}}^{2k-2}.
\end{gather*}

Теперь рассмотрим случай, когда шары неразличимы. В этом случае значение индикатора $P_i$ будет равнятсья $(m-1)^{k-1}$ так как по сути мы просто забываем про один
шар и ящик, общее число разбиений можно посчитать по формуле шаров и перегородок и получить $\binom{k+1}{m-1}$, итого 
    \[P_i = \frac{(m-1)^{k-1}}{\binom{k+1}{m-1}}.\]
А значит матожидание будет равно 
    \[E\xi = m \cdot \binom{k+1}{m-1}.\]
Посчитаем дисперсию:
\begin{gather*}
    E(\xi - E\xi)^2 = E\xi^2 - \brackets{E\xi}^2 = E\xi^2 - \brackets{\frac{(m-1)^{k-1}}{\binom{k+1}{m-1}}}^2 = 
    E(\sum_{i=1}^{m}P_i)^2 - \brackets{\frac{(m-1)^{k-1}}{\binom{k+1}{m-1}}}^2 = \\ 
    = \brackets{m\cdot\frac{(m-1)^{k-1}}{\binom{k+1}{m-1}}}^2 - \brackets{\frac{(m-1)^{k-1}}{\binom{k+1}{m-1}}}^2.
\end{gather*}

\i Рассмотрим индикаторы $P_i$ того, что на $i$-том шагу вынули последний белый шарик. Для $i < k$ $P_i = 0$, для остальных $P_i$ равно 1 с вероятностью 
$\frac{k!(n-k)!\binom{i-1}{k-1}}{n!}$ так как мы среди $n!$ равновероятных расстановок выбираем те, где на $i$-той позиции стоит белвый шар (ещё выбираем позиции
среди $i-1$ первых для остальных, и порядок шаров нас не интересует). Тогда матожидание будет равно сумме матожиданий индикаторов умноженных на номер хода
    \[E\xi = \sum_{i = k}^n \brackets{i \cdot frac{k!(n-k)!\binom{i-1}{k-1}}{n!}} = \frac{1}{\binom{n}{k}} \sum_{i = k}^n \brackets{i \cdot \binom{i-1}{k-1}}.\]
Теперь посчитаем дисперсию:
\begin{gather*}
    E(\xi - E\xi)^2 = E\xi^2 - \brackets{E\xi}^2 = 
    \sum_{i=k}^{n}\brackets{\frac{1}{\binom{n}{k}}\cdot i\cdot\brackets{\binom{i-1}{k-1}}}^2 - \brackets{\frac{1}{\binom{n}{k}} \sum_{i = k}^n \brackets{i \cdot \binom{i-1}{k-1}}}^2
\end{gather*}

\i Мы хотим доказать, что 
\[\frac{S_n - ES_n}{n} \substack{P\\\rightarrow} 0.\]
Воспользуемся неравенством Чебышева для случайной велисины $\frac{S_n}{n}$ и получим:
\begin{align*}
    P\brackets{\abs{\frac{S_n - ES_n}{n}} \geq a} \leq& \frac{E(\frac{S_n - ES_n}{n})^2}{a^2};\\ 
    P\brackets{\abs{\frac{S_n - ES_n}{n}} \geq a} \leq& \frac{E\brackets{\frac{S_n}{n}}^2 - \brackets{E\frac{S_n}{n}}^2}{a^2};\\ 
    P\brackets{\abs{\frac{S_n - ES_n}{n}} \geq a} \leq& \frac{E\brackets{S_n}^2 - \brackets{ES_n}^2}{n^2a^2};
\end{align*}
Теперь легко заметить, что при возрастании $n$ $P\brackets{\abs{\frac{S_n - ES_n}{n}} \geq a}$ стремится к нулю, а это ровно то, что мы и хотели доказать.